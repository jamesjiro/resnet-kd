{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "considerable-schema",
   "metadata": {},
   "source": [
    "# _Knowledge Distillation for Compression of ResNet50_\n",
    "***\n",
    "### _Santiago Giron_ <br>\n",
    "\n",
    "In the following notebook, I examine my initial results applying _Knowledge Distilation_ to residual networks for image classification in PyTorch. In Knowledge Distillation, a deep _teacher network_ is used to help train a shallower _student network_.\n",
    "\n",
    "## __ResNet50__\n",
    "\n",
    "As the teacher network, I've selected _ResNet50_ pretrained on ImageNet.\n",
    "> The model achieves an accuracy of 96.81 % on the CIFAR10 test set after training for 25 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loved-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Accuracy on validation set: 96.8100%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "valset = datasets.CIFAR10(\".\", train=False, download=True, \n",
    "                          transform=T.Compose([\n",
    "                              T.Resize(256),\n",
    "                              T.CenterCrop(224),\n",
    "                              T.ToTensor(),\n",
    "                              normalize,\n",
    "                          ]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(valset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "teacher_model = models.resnet50(pretrained=False)\n",
    "num_ftrs = teacher_model.fc.in_features\n",
    "teacher_model.fc = nn.Linear(num_ftrs, len(valset.classes))\n",
    "teacher_model.load_state_dict(torch.load(\"resnet50.pt\"))\n",
    "teacher_model.eval()\n",
    "teacher_model.to(device)\n",
    "\n",
    "def get_model_acc(model, dataloader):\n",
    "    running_corrects = 0\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    acc = running_corrects.double() / len(valset)\n",
    "    print(f'Accuracy on validation set: {100. * acc:.4f}%')\n",
    "\n",
    "get_model_acc(teacher_model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-rebecca",
   "metadata": {},
   "source": [
    "<br>In order to measure the latency of ResNet50, I profile the inference time of the model on some dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offshore-tracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference        17.30%       2.437ms        99.80%      14.063ms      14.063ms     666.241us         4.71%      14.133ms      14.133ms             1  \n",
      "                     aten::conv2d         2.42%     341.473us        40.20%       5.665ms     106.892us     205.049us         1.45%       8.546ms     161.238us            53  \n",
      "                aten::convolution         2.41%     339.169us        37.78%       5.324ms     100.449us     392.100us         2.77%       8.341ms     157.369us            53  \n",
      "               aten::_convolution         4.90%     690.114us        35.37%       4.985ms      94.050us     907.931us         6.41%       7.948ms     149.971us            53  \n",
      "          aten::cudnn_convolution        25.09%       3.535ms        29.36%       4.138ms      78.067us       6.709ms        47.38%       6.941ms     130.957us            53  \n",
      "                 aten::batch_norm         2.52%     355.121us        31.66%       4.462ms      84.183us     207.783us         1.47%       3.015ms      56.886us            53  \n",
      "     aten::_batch_norm_impl_index         8.47%       1.194ms        29.14%       4.107ms      77.483us     921.693us         6.51%       2.807ms      52.966us            53  \n",
      "                      aten::relu_         4.40%     620.580us         7.54%       1.062ms      21.675us     580.030us         4.10%       1.434ms      29.270us            49  \n",
      "                 aten::contiguous        13.42%       1.891ms        13.42%       1.891ms       4.450us       1.379ms         9.74%       1.379ms       3.245us           425  \n",
      "                 aten::threshold_         3.13%     441.477us         3.13%     441.477us       9.010us     854.177us         6.03%     854.177us      17.432us            49  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 14.091ms\n",
      "CUDA time total: 14.160ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "def get_latency_data(model):\n",
    "    input_batch = torch.randn(1, 3, 224, 224)\n",
    "    input_batch = input_batch.to(device)\n",
    "    model.to(device)\n",
    "\n",
    "    model(input_batch) # warm-up\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with profiler.profile(record_shapes=False, use_cuda=True) as prof:\n",
    "            with profiler.record_function(\"model_inference\"):\n",
    "                model(input_batch)\n",
    "\n",
    "    print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "\n",
    "get_latency_data(teacher_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-accordance",
   "metadata": {},
   "source": [
    "## __ResNet18__\n",
    "\n",
    "As the student network I have chosen _ResNet18_ pretrained on ImageNet. This is a significantly shallower network than ResNet50 with less capacity to generalize. ResNet50 has a top-1 error rate of 23.85% on ImageNet, whereas ResNet18 has a top-1 error rate of 30.24%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-parking",
   "metadata": {},
   "source": [
    "After fine-tuning the pretrained ResNet18 model for 25 epochs, I evaluate it's accuracy on CIFAR10.\n",
    "> The pretrained ResNet18 network achieves an accuracy of 94.95% on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sudden-arrival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 94.9500%\n"
     ]
    }
   ],
   "source": [
    "student_model = models.resnet18(pretrained=False)\n",
    "num_ftrs = student_model.fc.in_features\n",
    "student_model.fc = nn.Linear(num_ftrs, len(valset.classes))\n",
    "student_model.load_state_dict(torch.load(\"train_resnet18_25.pt\"))\n",
    "student_model.eval()\n",
    "student_model.to(device)\n",
    "\n",
    "get_model_acc(student_model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-kennedy",
   "metadata": {},
   "source": [
    "## _Optimized Model_\n",
    "To optimize the model, I apply Knowledge Distillation in the form proposed by Geoffrey Hinton et al. in _Distilling the Knowledge in a Neural Network_. This involved using ResNet50 as a larger \"cumbersome\" model to train the \"small\" model ResNet18. I used the weights of ResNet18 trained on ImageNet as initialization, then trained it with Knowledge Distillation on CIFAR10 for 25 epochs. The Knowledge Distillation loss is defined as:<br>\n",
    ">$$\n",
    "\\mathcal{L}(x;W) = \\alpha * \\mathcal{H}(y, \\sigma(z_s; T=1)) + \\beta * \\mathcal{H}(\\sigma(z_c; T=\\tau), \\sigma(z_s, T=\\tau))\n",
    "$$\n",
    "(source: https://intellabs.github.io/distiller/knowledge_distillation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-desperate",
   "metadata": {},
   "source": [
    "Here $x$ is the input, $W$ are the small model's parameters, $y$ is the ground truth label. $\\mathcal{H}$ is the cross-entropy loss and $\\sigma$ is the softmax function parameterized by the temperature $T$. $z_s$ and $z_c$ are the logits of the \"small\" model and the \"cumbersome\" model respectively. The first term on the right is the cross-entropy of the small model's output and the target, and the second term is the cross-entropy of the small model outputs and the large model outputs. The total loss is a weighted average parameterized by coefficients $\\alpha$ and $\\beta$.<br>\n",
    "\n",
    "I trained ResNet18 using the Knowledge Distillation loss presented above, substituting cross-entropy for the Kulback-Leibler divergence loss function. I used a temperature $T$ of 10 and an $\\alpha$ of 0.2, with $\\beta = 1 - \\alpha$. Hinton et. al report better results with $\\alpha$ significanly smaller than $\\beta$. After some experimentation with the temperature $T$, I found that setting it to 10 produced adequate results.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-rider",
   "metadata": {},
   "source": [
    "Below is a comparison of the number of model parameters in the teacher and student networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "minimal-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 parameters: 23,528,522\n"
     ]
    }
   ],
   "source": [
    "resnet50_params = sum(param.numel() for param in teacher_model.parameters())\n",
    "print(f'ResNet50 parameters: {resnet50_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gentle-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18 parameters: 11,181,642\n",
      "47.52% of the parameters of ResNet50.\n"
     ]
    }
   ],
   "source": [
    "resnet18_params = sum(param.numel() for param in student_model.parameters())\n",
    "print(f'ResNet18 parameters: {resnet18_params:,}')\n",
    "print(f'{100 * (resnet18_params/resnet50_params):.2f}% of the parameters of ResNet50.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-shepherd",
   "metadata": {},
   "source": [
    ">ResNet18 has __52.48% fewer parameters__ than ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "falling-tissue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 95.4000%\n"
     ]
    }
   ],
   "source": [
    "distil_model = models.resnet18(pretrained=False)\n",
    "num_ftrs = distil_model.fc.in_features\n",
    "distil_model.fc = nn.Linear(num_ftrs, len(valset.classes))\n",
    "distil_model.load_state_dict(torch.load(\"distil_resnet18_25.pt\"))\n",
    "distil_model.eval()\n",
    "distil_model.to(device)\n",
    "\n",
    "get_model_acc(distil_model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "understood-western",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference        18.29%       1.044ms        99.18%       5.661ms       5.661ms     482.272us         7.86%       5.924ms       5.924ms             1  \n",
      "                     aten::conv2d         2.54%     145.160us        41.53%       2.370ms     118.511us      97.505us         1.59%       3.828ms     191.378us            20  \n",
      "                aten::convolution         2.44%     139.185us        38.98%       2.225ms     111.253us      98.559us         1.61%       3.730ms     186.502us            20  \n",
      "               aten::_convolution         4.69%     267.421us        36.55%       2.086ms     104.294us     185.280us         3.02%       3.631ms     181.574us            20  \n",
      "          aten::cudnn_convolution        26.03%       1.486ms        30.76%       1.755ms      87.771us       3.299ms        53.78%       3.397ms     169.851us            20  \n",
      "                 aten::batch_norm         2.61%     149.241us        26.96%       1.539ms      76.946us     102.879us         1.68%       1.079ms      53.949us            20  \n",
      "     aten::_batch_norm_impl_index         8.44%     481.907us        24.35%       1.390ms      69.484us     353.313us         5.76%     976.096us      48.805us            20  \n",
      "           aten::cudnn_batch_norm         8.11%     462.709us        10.47%     597.338us      29.867us     392.350us         6.40%     392.350us      19.618us            20  \n",
      "                 aten::contiguous         8.79%     501.904us         8.79%     501.904us       3.117us     381.505us         6.22%     381.505us       2.370us           161  \n",
      "                      aten::relu_         4.20%     239.452us         7.04%     402.095us      23.653us     192.864us         3.14%     335.392us      19.729us            17  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.708ms\n",
      "CUDA time total: 6.134ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_latency_data(distil_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-window",
   "metadata": {},
   "source": [
    "The distilled ResNet18 model achieves an accuracy of 95.4% CIFAR10.\n",
    "> The inference speed is roughly __2.3x__ faster than ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-wallet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
